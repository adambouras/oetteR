



#' @title calculates maximum difference in group means and medians
#' @description used as a helper function for f_stat_anova
#' @param df dataframe
#' @param col_group character vector denoting grouping variable
#' @param col_variable character vector denoting variable
#' @return dataframe
#' @examples
#' set.seed(1)
#' df = tibble( fct = sample(LETTERS[1:5], 100, replace = T)
#'              , v1  = 1
#'              , v2  = rnorm(100, 4)
#'              , v3  = c( rep(3, 50), rep(8,50) )
#' )
#'
#' col_group = 'fct'
#'
#' f_stat_diff_of_means_medians(df, col_group, 'v1') %>%
#'   bind_rows( f_stat_diff_of_means_medians(df, col_group, 'v2') ) %>%
#'   bind_rows( f_stat_diff_of_means_medians(df, col_group, 'v3') )
#' @rdname f_stat_diff_of_means_medians
#' @export
f_stat_diff_of_means_medians = function(df, col_group, col_variable){


  data = df %>%
    select( group = one_of(col_group), variable = one_of(col_variable) )%>%
    mutate ( variable = f_manip_bring_to_pos_range(variable) ) %>%
    group_by( group ) %>%
    summarise( means     = mean(variable,   na.rm = T)
               , medians = median(variable, na.rm = T) ) %>%
    ungroup() %>%
    summarise( variable               = col_variable
               , diff_of_means        = max(means) - min(means)
               , diff_of_means_perc   = ( ( max(means) - min(means) ) /max(means) ) *100
               , diff_of_medians      = max(medians) - min(medians)
               , diff_of_medians_perc = ( ( max(medians) - min(medians) ) /max(means) ) *100    )


  return(data)
}

#' @title generate a datatframe with anova results from a data_ls list
#' @description returns a dataframe with shapiro, anova und kruskal p values
#'   supplemented with maximum difference of means and medians between groups
#'@param data_ls data_ls object generated by f_clean_data(), or a named list
#'  list( data = <dataframe>, numericals = < vector with column names of
#'  numerical columns>)
#' @param col_group character vector denoting grouping variable
#' @param boxcox perform analysis on boxcox-transformed or numerical variables
#' @return dataframe
#' @examples
#' df_anova = data_ls = f_clean_data(mtcars) %>%
#'   f_stat_anova('cyl')
#'
#' df_anova
#' @seealso \code{\link[stringr]{str_c}}
#' \code{\link[purrr]{map}},\code{\link[purrr]{map_dbl}}
#' \code{\link{f_stat_anova}}
#' @rdname f_anova_stats
#' @export
#' @importFrom stringr str_c
#' @importFrom purrr map map_dbl
f_stat_anova = function(data_ls, col_group, boxcox = F) {

  if( ! col_group %in% data_ls$categoricals ){
    stop('grouping variable not in categoricals')
  }

  if( is.null(data_ls$numericals) | is_empty(data_ls$numericals) ){
    return()
  }

  if( boxcox == T & ! is.null(data_ls$boxcox) ){

    variables = data_ls$boxcox_names
    data = data_ls$boxcox_data

  }else{
    variables = data_ls$numericals
    data = data_ls$data

  }

  formula = stringr::str_c('value~',col_group) %>%
    as.formula()

  df_anova = data %>%
    as_tibble() %>%
    select( one_of( c(col_group, variables) ) ) %>%
    gather(key = 'variable', value = 'value', one_of( variables ) ) %>%
    group_by( variable ) %>%
    filter( sd(value) != 0 ) %>%
    nest( one_of(col_group), value) %>%
    mutate( model_anova     = purrr::map( data, ~aov( formula, data = .))
            , summary_anova = purrr::map( model_anova, summary)
            , summary_anova = purrr::map( summary_anova
                                          , function(x) x[[1]])
            , anova_pval    = purrr::map(summary_anova, 'Pr(>F)')
            , anova_pval    = purrr::map_dbl(anova_pval
                                             , function(x) x[1])
            , model_kruskal = purrr::map( data, ~kruskal.test(formula, data = .) )
            , kruskal_pval  = purrr::map_dbl(model_kruskal, 'p.value')
            , model_shapiro = purrr::map(data, function(x) f_stat_shapiro( x$value ) )
            , shapiro_stat  = purrr::map_dbl(model_shapiro,'statistic')
            , shapiro_pval  = purrr::map_dbl(model_shapiro,'p.value')
            , diff_df       = purrr::map( data, f_stat_diff_of_means_medians, col_group = col_group, col_variable = 'value') ) %>%
    unnest(diff_df) %>%
    select(variable
           , shapiro_stat
           , shapiro_pval
           , anova_pval
           , kruskal_pval
           , diff_of_means
           , diff_of_means_perc
           , diff_of_medians
           , diff_of_medians_perc
    )

  return(df_anova)
}


#' @title calculate the maximal difference in frequencies between to categorical variables
#' @description used as a helper function for f_stat_chi_square
#' @param df dataframe containing both avariables
#' @param col_var1 character vector denoting variable column 1
#' @param col_var2 character vector denoting variable column 2
#' @return dataframe
#' @examples
#' data_ls = f_clean_data(mtcars)
#' df_chi_squ = f_stat_max_diff_of_freq(data_ls$data, 'cyl', 'gear')
#' @rdname f_stat_max_diff_of_freq
#' @export
f_stat_max_diff_of_freq = function(df, col_var1, col_var2){

  t = table( df[[col_var1]], df[[col_var2]] ) %>%
    as_tibble() %>%
    group_by( Var1 ) %>% #Var1 and Var2 are the automatically assigneed column names
    mutate ( diff_var1          = ( max(n)-min(n) )
             , diff_var1_perc = ( ( max(n)-min(n))/ max(n) *100)
    ) %>%
    group_by( Var2 ) %>%
    mutate ( diff_var2          = ( max(n)-min(n) )
             , diff_var2_perc = ( ( max(n)-min(n))/ max(n) *100)
    ) %>%
    ungroup()%>%
    summarise( max_diff_freq          = max( c(diff_var1, diff_var2) )
               , max_diff_freq_perc  = max( c(diff_var1_perc, diff_var2_perc) )
    )
}


#' @title generate a datatframe with chi square results from a data_ls list
#' @description FUNCTION_DESCRIPTION
#'@param data_ls data_ls object generated by f_clean_data(), or a named list
#'  list( data = <dataframe>, numericals = < vector with column names of
#'  numerical columns>)
#' @param col_group character vector denoting grouping variable
#' @return dataframe
#' @examples
#' data_ls = f_clean_data(mtcars)
#' df_chi_squ = f_stat_chi_square(data_ls, 'cyl')
#' df_chi_squ
#' @seealso
#'  \code{\link[purrr]{is_empty}},\code{\link[purrr]{map}},\code{\link[purrr]{map_dbl}}
#' @rdname f_stat_chi_square
#' @export
#' @importFrom purrr is_empty map map_dbl
f_stat_chi_square = function(data_ls, col_group) {

  if( ! col_group %in% data_ls$categoricals ){
    stop('grouping variable not in categoricals')
  }

  data = data_ls$data

  variables = data_ls$categoricals[!data_ls$categoricals == col_group]

  if(purrr::is_empty(variables)) return()

  df_chi = data %>%
    as_tibble() %>%
    select( one_of( c(col_group, variables) ) ) %>%
    gather(key = 'variable', value = 'value', one_of( variables  ) ) %>%
    group_by( variable ) %>%
    nest( one_of( col_group ), value) %>%
    mutate(  model_chi = purrr::map( data, ~chisq.test(x = .[[col_group]]
                                                       , y = .[['value']]
    ) )
    ,chi_pval  = purrr::map_dbl(model_chi, 'p.value')
    ,diff_df   = purrr::map(data, f_stat_max_diff_of_freq, col_group, 'value')  ) %>%
    unnest(diff_df) %>%
    select(variable, chi_pval, max_diff_freq, max_diff_freq_perc)

  return(df_chi)
}

#' @title combines anova with chi square results into single dataframe
#' @description keeps wither the anova or the kruskal p value depending on the
#'   results of the shapiro test (shapiro_stat > 0.9 p_val > 0.05) and keeps
#'   the difference of percent of the mean. Still works if one of the input
#'   dataframes is NULL
#' @param df_anova dataframe created with f_stat_anova, Default: NULL
#' @param df_chi_square dataframe created with f_stat_chi_square(), Default: NULL
#' @return OUTPUT_DESCRIPTION
#' @details DETAILS
#' @examples
#'  data_ls = f_clean_data(mtcars)
#'  df_chi_squ = f_stat_chi_square(data_ls, 'cyl')
#'  df_anova = f_stat_anova(data_ls, 'cyl')
#'  df_comb = f_stat_combine_anova_with_chi_square(df_anova, df_chi_squ)
#'  df_comb
#'  df_comb = f_stat_combine_anova_with_chi_square(df_anova)
#'  df_comb
#'  df_comb = f_stat_combine_anova_with_chi_square(df_chi_square = df_chi_squ)
#'  df_comb
#' @rdname f_stat_combine_anova_with_chi_square
#' @export

f_stat_combine_anova_with_chi_square = function(df_anova = NULL, df_chi_square = NULL){

  if( ! is_empty(df_anova) | ! is.null(df_anova) ) {
    df_anova = df_anova %>%
      mutate( final_p_value = ifelse(shapiro_stat > 0.9 & shapiro_pval > 0.05
                                     , anova_pval, kruskal_pval) ) %>%
      select(variable, p_value = final_p_value , diff_perc = diff_of_means_perc)
  }

  if( ! is_empty(df_chi_square) | ! is.null(df_chi_square) ) {
    df_chi_square = df_chi_square %>%
      select(variable, p_value = chi_pval, diff_perc = max_diff_freq_perc)
  }

  # bind_rows takes NULL without error
  df_comb = df_anova %>%
  bind_rows( df_chi_square )%>%
  arrange(p_value)

}

#'@title analyse group difference of dataset
#'@description returns a full analysis as a taglist inluding all features with
#'  p_values, medians, means, percentages and counts, as well as plots passing
#'  the treshold values
#'@param data_ls data_ls object generated by f_clean_data(), or a named list
#'  list( data = <dataframe>, numericals = < vector with column names of
#'  numerical columns>)
#'@param col_group character vector denoting grouping columns
#'@param tresh_p_val p value threshold for plots, Default: 0.05
#'@param thresh_diff_perc minimum percent difference threshold for plots,
#'  Default: 3
#'@return taglist
#' @examples
#' \dontrun{
#'  data_ls = f_clean_data(mtcars)
#'  taglist = f_stat_group_ana_taglist(data_ls, 'cyl')
#'  f_plot_obj_2_html(taglist, type = "taglist", output_file = 'test_me', title = 'Plots')
#'  file.remove('test_me.html')
#' }
#'@seealso \code{\link[plotly]{ggplotly}}
#'  \code{\link[htmltools]{tagList}},\code{\link[htmltools]{h1}},\code{\link[htmltools]{h2}}
#'
#'
#'@rdname f_stat_group_ana_taglist
#'@export
#'@importFrom plotly ggplotly
#'@importFrom htmltools tagList h1 h2 h3 h4 h5 h6
f_stat_group_ana_taglist = function(data_ls, col_group, tresh_p_val = 0.05, thresh_diff_perc = 3 ){

  df_anova = f_stat_anova( data_ls, col_group )
  df_chi   = f_stat_chi_square( data_ls, col_group )
  df_comb  = f_stat_combine_anova_with_chi_square( df_anova, df_chi ) %>%
    mutate( stars = f_stat_stars(p_value) ) %>%
    select( variable, stars, p_value, diff_perc )

  df_means = f_stat_group_mean_medians(data_ls, col_group)
  df_perc  = f_stat_group_counts_percentages(data_ls, col_group)



  f_plot = function( var, title, col_group, data_ls ){


    caption = '* P:0.05, ** P:0,005, *** P:0.001'


    if(var %in% data_ls$numericals){


      p = f_plot_hist( var, data_ls, col_group, graph_type = 'violin') %>%
        plotly::ggplotly( tooltip = c('y','fill') )

      taglist = f_html_padding(p, 4, title, caption = caption )

    }else{

      p = f_plot_hist( var, data_ls, col_group, graph_type = 'bar' , y_axis = 'count' ) %>%
        plotly::ggplotly( tooltip = c('y','fill') )

      l1 = f_html_padding(p, 4, title, subtitle = 'Counts' )

      p = f_plot_hist( var, data_ls, col_group, graph_type = 'bar' , y_axis = 'density' ) %>%
        plotly::ggplotly( tooltip = c('y','fill') )

      l2 = f_html_padding(p, subtitle = 'Probabilities', caption = caption )

      taglist = htmltools::tagList( l1, l2)


    }

    return( taglist )

  }

  plots = df_comb %>%
    filter( p_value <= tresh_p_val & diff_perc >= thresh_diff_perc) %>%
    mutate( stars = f_stat_stars( p_value )
            ,title = paste( variable, stars)
            , plot = map2( variable, title, f_plot, col_group, data_ls )
            ) %>%
    .$plot

  tab_all = f_datatable_universal( df_comb, round_other_nums = 2 ) %>%
    f_html_padding( 3, title ='All features'
                    , subtitle = paste('grouped by:', col_group), pad_after = 3 )

  tab_mean = f_datatable_universal( df_means, round_other_nums = 2 ) %>%
    f_html_padding( 3, title ='Means and Medians of numerical features'
                    , subtitle = paste('grouped by:', col_group))

  tab_perc = f_datatable_universal( df_perc, round_other_nums = 2 ) %>%
    f_html_padding(  title ='Counts and percentages of categorical features'
                    , subtitle = paste('grouped by:', col_group), pad_after = 2 )


  taglist = htmltools::tagList()
  taglist[[1]] = htmltools::h1( paste('Differences Between "', col_group, '" Groups') )
  taglist[[2]] = tab_all
  taglist[[3]] = htmltools::h2( paste( 'Plots for features with significant differences of minimum'
                                       , thresh_diff_perc, '% sorted by P Value' ) )
  taglist[[4]] = plots
  taglist[[5]] = f_html_breaks(5)
  taglist[[6]] = htmltools::h2( 'Summary Tables' )
  taglist[[7]] = tab_mean
  taglist[[8]] = tab_perc

  return( taglist )

}

#' @title create a aggregated data frame with means and medians for numerical variables
#'@param data_ls data_ls object generated by f_clean_data(), or a named list
#'  list( data = <dataframe>, numericals = < vector with column names of
#'  numerical columns>)
#' @param col_group character vector denoting grouping columns
#' @return dataframe
#' @examples
#' f_clean_data( mtcars) %>%
#'  f_stat_group_mean_medians('cyl')
#' @rdname f_stat_group_mean_medians
#' @export
f_stat_group_mean_medians = function(data_ls, col_group){

  if( ! col_group %in% data_ls$categoricals ){
    stop('grouping variable not in categoricals')
  }

  if( is.null(data_ls$numericals) | is_empty(data_ls$numericals) ){
    return()
  }

  sym_group = as.name( col_group )

  df = data_ls$data %>%
    select( one_of(data_ls$numericals, col_group) ) %>%
    group_by_(col_group) %>%
    gather( key = 'variable', value = 'value', - one_of(col_group) ) %>%
    mutate( value = as.numeric(value) )

  df_mean = df %>%
    group_by_( col_group, 'variable' ) %>%
    summarize( mean = mean(value) ) %>%
    rename( !! as.name( paste0('mean_', col_group) )  := !!sym_group ) %>%
    spread_( key = paste0('mean_', col_group), value = 'mean', sep = '_' )

  df_median = df %>%
    group_by_( col_group, 'variable' ) %>%
    summarize( median = median(value) ) %>%
    rename( !! as.name( paste0('median_', col_group) )  := !!sym_group ) %>%
    spread_( key = paste0('median_', col_group), value = 'median', sep = '_' )

  df_p_val = f_stat_anova(data_ls, col_group) %>%
    f_stat_combine_anova_with_chi_square( ) %>%
    mutate( stars = f_stat_stars(p_value) ) %>%
    select( stars, everything() )

  df_comb = df_mean %>%
    left_join( df_median ) %>%
    left_join( df_p_val ) %>%
    arrange( p_value )

  return(df_comb)
}

#' @title create a aggregated data frame with percentagers and counts for categorical variables
#'@param data_ls data_ls object generated by f_clean_data(), or a named list
#'  list( data = <dataframe>, numericals = < vector with column names of
#'  numerical columns>)
#' @param col_group character vector denoting grouping columns
#' @return dataframe
#' @examples
#' f_clean_data( mtcars) %>%
#'  f_stat_group_counts_percentages('cyl')
#' @rdname f_stat_group_counts_percentages
#' @export
f_stat_group_counts_percentages = function(data_ls, col_group){

  if( ! col_group %in% data_ls$categoricals ){
    stop('grouping variable not in categoricals')
  }

  if( is.null(data_ls$categoricals) | is_empty(data_ls$categoricals) ){
    return()
  }

  sym_group = as.name(col_group)

  df = data_ls$data %>%
    select( one_of(data_ls$categoricals, col_group) ) %>%
    gather( key = 'variable', value = 'value' , -one_of(col_group) ) %>%
    mutate( value =  paste0(variable, '_', value) ) %>%
    group_by_( col_group, 'variable', 'value' ) %>%
    count() %>%
    group_by_( col_group )

  df_n = df %>%
    ungroup() %>%
    mutate( !! sym_group := paste0( col_group, '_', !! sym_group, '_count') ) %>%
    spread( key = !! sym_group, value = n, fill = 0 )

  df_perc = df %>%
    group_by(variable) %>%
    mutate( !! sym_group := paste0( col_group, '_', !! sym_group, '_perc')
            , perc = n / sum(n) *100 ) %>%
    select( -n ) %>%
    spread( key = !! sym_group, value = perc, fill = 0 )

  df_p_val = f_stat_chi_square(data_ls, col_group) %>%
    f_stat_combine_anova_with_chi_square( df_chi_square = .) %>%
    mutate( stars = f_stat_stars(p_value) ) %>%
    select( stars, everything() )

  df_comb = df_n %>%
    left_join( df_perc ) %>%
    left_join( df_p_val ) %>%
    arrange( p_value )

  return(df_comb)
}

#' @title calculate significant level from p value
#' @description * P:0.05, ** P:0,005, *** P:0.001
#' @param p_value numeric
#' @return character vector
#' @examples
#' f_stat_stars(0.06)
#' f_stat_stars(0.05)
#' f_stat_stars(0.005)
#' f_stat_stars(0.001)
#' @rdname f_stat_stars
#' @export
f_stat_stars = function(p_value){

  ifelse( p_value <= 0.001, '***'
          , ifelse(p_value <= 0.005, '**'
          , ifelse(p_value <= 0.05, '*', 'ns') ) )

}


#' @title wrapper for shapiro.test()
#' @description shapiro.test i slimited to <5000 sample size and raises an error
#'   if sd(x) == 0. Wrapper samples from input vector and returns a list object
#'   with NA parameters if sd(x) == 0.
#' @param vec numeric vector
#' @return shapiro.test object or list( statistic = NA, p.value = NA )
#' @examples
#' f_stat_shapiro( rnorm(1000, 10, 1) )
#' f_stat_shapiro( runif(1000, 1, 10) )
#' @rdname f_stat_shapiro
#' @export
f_stat_shapiro = function(vec){

  if( length(vec) > 5000 ){
    vec = sample( vec, 5000, replace = F)
  }

  if( sd(vec) == 0 ){

    m = list( statistic = NA, p.value = NA )

  }else{

    m = shapiro.test(vec)
  }

  return(m)
}

